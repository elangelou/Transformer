{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "import LayerNorm\n",
    "from LayerNorm import Config, cfg\n",
    "\n",
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = LayerNorm.reference_gpt2.to_tokens(reference_text).to(LayerNorm.device)\n",
    "print(tokens.shape)\n",
    "\n",
    "class Embed(t.nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = t.empty((cfg.d_vocab, cfg.d_model))\n",
    "\n",
    "    def one_hot(self, tokens):\n",
    "        vectors = []\n",
    "        for token in tokens.squeeze():\n",
    "            list = [0]\n",
    "            list = list * 50257\n",
    "            list[token] = 1\n",
    "            vector = t.tensor(list)\n",
    "            vectors += vector\n",
    "        tensor = t.tensor(vectors)\n",
    "        return tensor\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        vocab_size = self.W_E.shape[0]\n",
    "\n",
    "        one_hot = t.zeros(batch_size, seq_len, vocab_size, device=tokens.device)\n",
    "        one_hot.scatter_(2, tokens.unsqueeze(-1), 1)\n",
    "\n",
    "        print(\"tokens shape before einsum:\", one_hot.shape)\n",
    "        print(\"self.W_E shape:\", self.W_E.shape)\n",
    "\n",
    "        output = t.einsum(\"bsv, ve->bse\", one_hot, self.W_E)\n",
    "\n",
    "        print(\"output shape after einsum:\", output.shape)\n",
    "        return output\n",
    "\n",
    "       \n",
    "       \n",
    "        # tokens = self.one_hot(tokens)\n",
    "        # print(\"self.W_E shape:\", self.W_E.shape)\n",
    "        # output = t.einsum(\"ji,jk->ik\", self.W_E, tokens.T)\n",
    "        # print(\"tokens shape after einsum:\", tokens.shape)\n",
    "        # return output.T\n",
    "\n",
    "# [seq, dim]\n",
    "embed = Embed(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
